{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 1주차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "12.4\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[3666, 1438,  318]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(encoded_input['input_ids'], max_length=50)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My name is John. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3666, 1438,  318, 1757,   13,  314, 1101,  257,  582,  286, 1793,   13,\n",
       "          314, 1101,  257,  582,  286, 1793,   13,  314, 1101,  257,  582,  286,\n",
       "         1793,   13,  314, 1101,  257,  582,  286, 1793,   13,  314, 1101,  257,\n",
       "          582,  286, 1793,   13,  314, 1101,  257,  582,  286, 1793,   13,  314,\n",
       "         1101,  257]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 2주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch를 활용하여 Transformer 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 준비\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(num_epochs):\\n    optimizer.zero_grad()\\n    output = model(src, tgt)\\n    loss = criterion(output, tgt_labels)\\n    loss.backward()\\n    optimizer.step()\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, tgt)\n",
    "    loss = criterion(output, tgt_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 모델 활용하기\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "cache_path = 'D:\\Anaconda3_envs\\SpartaCodingClub\\SpartaCodingClub\\main_camp'\n",
    "\n",
    "torch.hub.set_dir(cache_path)\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', cache_dir=cache_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2', cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Once upon a time'\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=50, num_return_sequences = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 3주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert_Basic.py & transformers_code.py 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 4주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 모델로 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time the same happened to the ancient Egyptian, the Egyptian man who had long ago vanquished the evil gods is made a mortal for each of a man's deeds. Now it is clear that the same god is given immortality to a man that\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# GPT-2 기반 텍스트 생성 파이프라인 로드\n",
    "generator = pipeline(\"text-generation\", model='gpt2', device=device)\n",
    "\n",
    "# 텍스트 생성\n",
    "generated_text = generator(\"Once upon a time\", max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 안녕! 만나서 반가워! 혹시 여기 올 때 \"전자우체국\"에서 비행기로 오셨나요? 아니면 빛의 속도로 워프하셨나요?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕?\"}  \n",
    "  ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)\n",
    "\n",
    "# 안녕하세요! 만나서 반가워요. 저랑 얘기하다가 재미 없으면 이렇게 생각해보세요: 적어도 엉덩이에 꼬리 달린 원숭이와는 다르게, 저는 평범하게 무리하지 않거든요! 뭐든 물어보세요, 도와드릴게요! 😄 \n",
    "\n",
    "# 강사의 한마디: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:53<00:00,  7.58s/it]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Stable Diffusion 파이프라인 로드\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to('cuda')  # GPU 사용\n",
    "\n",
    "# 텍스트 설명을 기반으로 이미지 생성\n",
    "prompt = \"A futuristic cityscape with flying cars at sunset\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# 생성된 이미지 저장 및 출력\n",
    "image.save(\"generated_image.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 5주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API 심화 및 간단한 실습 (FastAPI 활용) -> FastAPI.py 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT와 ElevenLabs 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 안녕하세요, 윤수용님. 법률 상담이 필요하신가요? 어떤 점이 궁금하신지 말씀해주시면 도움이 될 수 있는 방향으로 안내해드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 API 키 가져오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API 키를 못 가져왔을 경우 에러 표시 \n",
    "if api_key is None:\n",
    "    raise ValueError('Failed loading')\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = api_key\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 변호사야 나에게 법적인 상담을 해줘\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요 저는 윤수용입니다.\"}  \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대답:  안녕하세요! 무엇을 도와드릴까요? 법률 관련 상담이 필요하신가요?\n",
      "대답:  부가가치세(VAT)는 상품이나 서비스가 생산 및 유통되는 과정에서 발생하는 부가가치에 대해 부과되는 세금을 말합니다. 한국에서는 사업자가 소비자로부터 상품이나 서비스 판매 시 부가가치세를 징수하고, 이후 정부에 이를 납부합니다. 기본적으로는 판매 가격에 10%의 세율이 적용됩니다.\n",
      "\n",
      "부가가치세의 특징 중 하나는 사업자가 매입 시 부담했던 부가가치세를 공제받을 수 있다는 점입니다. 즉, 사업자는 판매 시 징수한 부가가치세에서 매입 시 납부한 부가가치세를 차감한 금액만큼을 국가에 납부하게 됩니다. 이를 통해 이중과세를 방지하고, 세금 부담이 최종 소비자에게 전가되도록 설계되어 있습니다.\n",
      "\n",
      "부가가치세는 대부분의 상품과 서비스에 적용되지만, 일부 면세 대상도 있습니다. 예를 들어, 기초 식료품, 의료 서비스, 교육 서비스 등은 부가가치세가 면제될 수 있습니다. 사업자는 정기적으로 부가가치세 신고와 납부를 해야 하며, 이를 통해 국가의 세수 확보와 경제 활동의 투명성을 높이는 데 기여합니다.\n",
      "대답:  즐거운 대화였습니다! 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "system_message =  {\n",
    "    \"role\": \"system\", \"content\": \"너는 변호사야 나에게 법률적인 상담을 해줘. 그리고 주의사항은 말하지마. 한국법을 기준으로 \"\n",
    "}\n",
    "\n",
    "messages = [system_message]\n",
    "\n",
    "while True :\n",
    "    user_input = input(\"사용자 전달:\")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"대답:  즐거운 대화였습니다! 감사합니다!\")\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\" : \"user\" , \"content\" : user_input })\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    reply = completion.choices[0].message.content\n",
    "    print(\"대답:  \" + reply)\n",
    "    messages.append({\"role\" : \"assistant\" , \"content\" : reply })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        open output_audio.mp3\n",
      "    지정한 장치가 열려 있지 않거나 MCI에서 인식되지 않습니다.\n",
      "\n",
      "    Error 263 for command:\n",
      "        close output_audio.mp3\n",
      "    지정한 장치가 열려 있지 않거나 MCI에서 인식되지 않습니다.\n",
      "Failed to close the file: output_audio.mp3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Wrote audio to output_audio.mp3\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3378, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_25420\\379441704.py\", line 53, in <module>\n",
      "    playsound.playsound(output_filename)\n",
      "  File \"d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\playsound.py\", line 72, in _playsoundWin\n",
      "  File \"d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\playsound.py\", line 64, in winCommand\n",
      "    url   = NSURL.URLWithString_(sound)\n",
      "playsound.PlaysoundException: \n",
      "    Error 263 for command:\n",
      "        open output_audio.mp3\n",
      "    지정한 장치가 열려 있지 않거나 MCI에서 인식되지 않습니다.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 1997, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1112, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 1006, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 859, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 812, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\ultratb.py\", line 730, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\USER\\AppData\\Roaming\\Python\\Python39\\site-packages\\executing\\executing.py\", line 168, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "import playsound\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 API 키와 URL 가져오기\n",
    "api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "url =os.getenv(\"ELEVENLABS_API_URL\")\n",
    "\n",
    "# API 키 or URL 을 못 가져왔을 경우 에러 표시 \n",
    "if api_key is None or url is None:\n",
    "    raise ValueError('Failed loading')\n",
    "\n",
    "output_filename = \"output_audio.mp3\"\n",
    "\n",
    "headers = {\n",
    "    \"xi-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "text = input(\"생성할 텍스트를 입력해주세요.\")\n",
    "\n",
    "# 음성 생성 요청을 보냅니다.\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.3,\n",
    "        \"similarity_boost\": 1,\n",
    "        \"style\": 1,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    audio_content = b\"\"\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            audio_content += chunk\n",
    "\n",
    "    segment = AudioSegment.from_mp3(io.BytesIO(audio_content))\n",
    "    segment.export(output_filename, format=\"mp3\")\n",
    "    print(f\"Success! Wrote audio to {output_filename}\")\n",
    "\n",
    "    # 오디오를 재생합니다.\n",
    "    playsound.playsound(output_filename)\n",
    "else:\n",
    "    print(f\"Failed to save file: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultralytics YOLO를 활용한 이미지 객체 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\USER\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpartaCodingClub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
