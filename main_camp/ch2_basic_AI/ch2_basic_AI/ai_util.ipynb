{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 1주차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "12.4\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[3666, 1438,  318]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(encoded_input['input_ids'], max_length=50)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My name is John. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3666, 1438,  318, 1757,   13,  314, 1101,  257,  582,  286, 1793,   13,\n",
       "          314, 1101,  257,  582,  286, 1793,   13,  314, 1101,  257,  582,  286,\n",
       "         1793,   13,  314, 1101,  257,  582,  286, 1793,   13,  314, 1101,  257,\n",
       "          582,  286, 1793,   13,  314, 1101,  257,  582,  286, 1793,   13,  314,\n",
       "         1101,  257]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 2주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch를 활용하여 Transformer 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 준비\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(num_epochs):\\n    optimizer.zero_grad()\\n    output = model(src, tgt)\\n    loss = criterion(output, tgt_labels)\\n    loss.backward()\\n    optimizer.step()\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, tgt)\n",
    "    loss = criterion(output, tgt_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 모델 활용하기\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "cache_path = 'D:\\Anaconda3_envs\\SpartaCodingClub\\SpartaCodingClub\\main_camp'\n",
    "\n",
    "torch.hub.set_dir(cache_path)\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', cache_dir=cache_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2', cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Once upon a time'\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=50, num_return_sequences = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 3주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert_Basic.py & transformers_code.py 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 4주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 모델로 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time the same happened to the ancient Egyptian, the Egyptian man who had long ago vanquished the evil gods is made a mortal for each of a man's deeds. Now it is clear that the same god is given immortality to a man that\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# GPT-2 기반 텍스트 생성 파이프라인 로드\n",
    "generator = pipeline(\"text-generation\", model='gpt2', device=device)\n",
    "\n",
    "# 텍스트 생성\n",
    "generated_text = generator(\"Once upon a time\", max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "# 결과 출력\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 안녕! 만나서 반가워! 혹시 여기 올 때 \"전자우체국\"에서 비행기로 오셨나요? 아니면 빛의 속도로 워프하셨나요?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘\"},\n",
    "    {\"role\": \"user\", \"content\": \"안녕?\"}  \n",
    "  ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)\n",
    "\n",
    "# 안녕하세요! 만나서 반가워요. 저랑 얘기하다가 재미 없으면 이렇게 생각해보세요: 적어도 엉덩이에 꼬리 달린 원숭이와는 다르게, 저는 평범하게 무리하지 않거든요! 뭐든 물어보세요, 도와드릴게요! 😄 \n",
    "\n",
    "# 강사의 한마디: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:53<00:00,  7.58s/it]\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Stable Diffusion 파이프라인 로드\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to('cuda')  # GPU 사용\n",
    "\n",
    "# 텍스트 설명을 기반으로 이미지 생성\n",
    "prompt = \"A futuristic cityscape with flying cars at sunset\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# 생성된 이미지 저장 및 출력\n",
    "image.save(\"generated_image.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI 모델 활용 5주차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API 심화 및 간단한 실습 (FastAPI 활용) -> FastAPI.py 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT와 ElevenLabs 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: 안녕하세요, 윤수용님. 법률 상담이 필요하신가요? 어떤 점이 궁금하신지 말씀해주시면 도움이 될 수 있는 방향으로 안내해드리겠습니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 API 키 가져오기\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API 키를 못 가져왔을 경우 에러 표시 \n",
    "if api_key is None:\n",
    "    raise ValueError('Failed loading')\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = api_key\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 변호사야 나에게 법적인 상담을 해줘\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요 저는 윤수용입니다.\"}  \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대답:  안녕하세요! 무엇을 도와드릴까요? 법률 관련 상담이 필요하신가요?\n",
      "대답:  부가가치세(VAT)는 상품이나 서비스가 생산 및 유통되는 과정에서 발생하는 부가가치에 대해 부과되는 세금을 말합니다. 한국에서는 사업자가 소비자로부터 상품이나 서비스 판매 시 부가가치세를 징수하고, 이후 정부에 이를 납부합니다. 기본적으로는 판매 가격에 10%의 세율이 적용됩니다.\n",
      "\n",
      "부가가치세의 특징 중 하나는 사업자가 매입 시 부담했던 부가가치세를 공제받을 수 있다는 점입니다. 즉, 사업자는 판매 시 징수한 부가가치세에서 매입 시 납부한 부가가치세를 차감한 금액만큼을 국가에 납부하게 됩니다. 이를 통해 이중과세를 방지하고, 세금 부담이 최종 소비자에게 전가되도록 설계되어 있습니다.\n",
      "\n",
      "부가가치세는 대부분의 상품과 서비스에 적용되지만, 일부 면세 대상도 있습니다. 예를 들어, 기초 식료품, 의료 서비스, 교육 서비스 등은 부가가치세가 면제될 수 있습니다. 사업자는 정기적으로 부가가치세 신고와 납부를 해야 하며, 이를 통해 국가의 세수 확보와 경제 활동의 투명성을 높이는 데 기여합니다.\n",
      "대답:  즐거운 대화였습니다! 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "system_message =  {\n",
    "    \"role\": \"system\", \"content\": \"너는 변호사야 나에게 법률적인 상담을 해줘. 그리고 주의사항은 말하지마. 한국법을 기준으로 \"\n",
    "}\n",
    "\n",
    "messages = [system_message]\n",
    "\n",
    "while True :\n",
    "    user_input = input(\"사용자 전달:\")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"대답:  즐거운 대화였습니다! 감사합니다!\")\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\" : \"user\" , \"content\" : user_input })\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    reply = completion.choices[0].message.content\n",
    "    print(\"대답:  \" + reply)\n",
    "    messages.append({\"role\" : \"assistant\" , \"content\" : reply })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Wrote audio to output_audio.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "import webbrowser\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# .env 파일에서 API 키와 URL 가져오기\n",
    "api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "url = os.getenv(\"ELEVENLABS_API_URL\")\n",
    "\n",
    "# API 키 or URL 을 못 가져왔을 경우 에러 표시 \n",
    "if api_key is None or url is None:\n",
    "    raise ValueError('Failed loading')\n",
    "\n",
    "output_filename = \"output_audio.mp3\"\n",
    "\n",
    "headers = {\n",
    "    \"xi-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "text = input(\"생성할 텍스트를 입력해주세요.\")\n",
    "\n",
    "# 음성 생성 요청을 보냅니다.\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.3,\n",
    "        \"similarity_boost\": 1,\n",
    "        \"style\": 1,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    audio_content = b\"\"\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            audio_content += chunk\n",
    "\n",
    "    segment = AudioSegment.from_mp3(io.BytesIO(audio_content))\n",
    "    segment.export(output_filename, format=\"mp3\")\n",
    "    print(f\"Success! Wrote audio to {output_filename}\")\n",
    "\n",
    "    # 오디오를 재생합니다.\n",
    "    webbrowser.open(output_filename)\n",
    "else:\n",
    "    print(f\"Failed to save file: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultralytics YOLO를 활용한 이미지 객체 탐지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 62.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# YOLOv8 모델 로드 (YOLOv8s)\n",
    "model = YOLO('yolov8n.pt')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹캠을 통해 실시간 객체 탐지\n",
    "cap = cv2.VideoCapture(0)  # 웹캠 캡처 시작\n",
    "cap.set(360, 480)\n",
    "# 웹캠 -> \n",
    "\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  # 프레임을 YOLOv8 모델에 입력하여 객체 탐지 수행\n",
    "  results = model(frame)\n",
    "  \n",
    "  # 이후 처리코드    \n",
    "  cv2.imshow('webcam', frame)\n",
    "\n",
    "  # 'q' 키를 누르면 종료\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "# 웹캠 종료 및 창 닫기\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV와 YOLO를 활용한 실시간 객체 탐지 서비스 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QWidget, QPushButton\n",
    "from PyQt5.QtCore import QTimer\n",
    "from PyQt5.QtGui import QImage, QPixmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCaptureWidget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # YOLOv8x 모델 로드 (YOLOv8x)\n",
    "        self.model = YOLO('yolov8x.pt')\n",
    "        \n",
    "        # UI 설정\n",
    "        self.setWindowTitle(\"실시간 객체 탐지\")\n",
    "        self.image_label = QLabel(self)\n",
    "        self.layout = QVBoxLayout()\n",
    "        self.layout.addWidget(self.image_label)\n",
    "\n",
    "        self.start_button = QPushButton(\"Start Webcam\", self)\n",
    "        self.start_button.clicked.connect(self.start_webcam)\n",
    "        self.layout.addWidget(self.start_button)\n",
    "\n",
    "        self.stop_button = QPushButton(\"Stop Webcam\", self)\n",
    "        self.stop_button.clicked.connect(self.stop_webcam)\n",
    "        self.layout.addWidget(self.stop_button)\n",
    "        self.setLayout(self.layout)\n",
    "        \n",
    "        # 웹캠 초기화\n",
    "        self.capture = None\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "    def stop_webcam(self):\n",
    "        \"\"\"웹캠을 중지하고 타이머를 멈춤\"\"\"\n",
    "        self.timer.stop()\n",
    "        if self.capture is not None:\n",
    "            self.capture.release()\n",
    "    \n",
    "    def start_webcam(self):\n",
    "        \"\"\"웹캠을 시작하고, 타이머를 시작하여 프레임을 주기적으로 읽음\"\"\"\n",
    "        self.capture = cv2.VideoCapture(0)  # 웹캠 장치 열기\n",
    "        self.timer.start(20)  # 20ms마다 프레임 업데이트 (50fps)\n",
    "\n",
    "    def update_frame(self):\n",
    "        \"\"\"웹캠에서 프레임을 읽어와서 YOLO 객체 탐지를 수행한 후 UI에 표시\"\"\"\n",
    "        ret, frame = self.capture.read()\n",
    "        if ret:\n",
    "            # YOLOv8 객체 탐지 수행\n",
    "            results = self.model(frame)\n",
    "            result = results[0]\n",
    "\n",
    "            # 바운딩 박스가 포함된 이미지를 가져옴\n",
    "            img_with_boxes = result.plot()\n",
    "\n",
    "            # OpenCV 이미지를 QImage로 변환\n",
    "            rgb_image = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "            h, w, ch = rgb_image.shape\n",
    "            bytes_per_line = ch * w\n",
    "            convert_to_Qt_format = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "\n",
    "            # QImage를 QLabel에 표시하기 위해 QPixmap으로 변환\n",
    "            self.image_label.setPixmap(QPixmap.fromImage(convert_to_Qt_format))\n",
    "    \n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"윈도우 닫을 때 웹캠 해제\"\"\"\n",
    "        if self.capture is not None:\n",
    "            self.capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication([])\n",
    "    window = VideoCaptureWidget()\n",
    "    window.show()\n",
    "    app.exec_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPT와 FastAPI를 활용한 챗 서비스 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request, Form\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from openai import OpenAI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# OpenAI API 클라이언트 설정\n",
    "client = OpenAI()\n",
    "\n",
    "# Jinja2 템플릿 설정\n",
    "templates = Jinja2Templates(directory=\"./app/templates\")\n",
    "\n",
    "# 정적 파일 서빙\n",
    "app.mount(\"/static\", StaticFiles(directory=\"./app/static\"), name=\"static\")\n",
    "\n",
    "# 초기 시스템 메시지 설정\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"너는 환영 인사를 하는 인공지능이야, 농담을 넣어 재미있게해줘\"\n",
    "}\n",
    "\n",
    "# 대화 내역을 저장할 리스트 초기화\n",
    "messages = [system_message]\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def get_chat_page(request: Request):\n",
    "    \"\"\"채팅 페이지 렌더링\"\"\"\n",
    "    conversation_history = [msg for msg in messages if msg[\"role\"] != \"system\"]\n",
    "    return templates.TemplateResponse(\"index.html\", {\"request\": request, \"conversation_history\": conversation_history})\n",
    "\n",
    "@app.post(\"/chat\", response_class=HTMLResponse)\n",
    "async def chat(request: Request, user_input: str = Form(...)):\n",
    "    \"\"\"사용자 메시지를 받아 OpenAI API 호출 및 응답 반환\"\"\"\n",
    "    global messages\n",
    "\n",
    "    # 사용자의 메시지를 대화 내역에 추가\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # OpenAI API 호출\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # AI의 응답 가져오기\n",
    "    assistant_reply = completion.choices[0].message.content\n",
    "\n",
    "    # AI의 응답을 대화 내역에 추가\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "    # 화면에 표시할 대화 내역에서 system 메시지를 제외하고 전달\n",
    "    conversation_history = [msg for msg in messages if msg[\"role\"] != \"system\"]\n",
    "\n",
    "    # 결과를 HTML로 반환 (대화 내역과 함께)\n",
    "    return templates.TemplateResponse(\"index.html\", {\n",
    "        \"request\": request,\n",
    "        \"conversation_history\": conversation_history\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음성 생성과 번역을 활용한 번역 서비스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5.QtCore import QUrl\n",
    "from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from pydub import AudioSegment\n",
    "import webbrowser\n",
    "import io\n",
    "\n",
    "class TranslatorApp(QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_ui()\n",
    "\n",
    "        # 번역 모델 로드\n",
    "        model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "        # API 설정\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.url = os.getenv(\"ELEVENLABS_API_URL\")\n",
    "\n",
    "        # 음성 재생기\n",
    "        self.player = QMediaPlayer()\n",
    "\n",
    "    def init_ui(self):\n",
    "        # UI 구성\n",
    "        self.text_input = QtWidgets.QLineEdit(self)\n",
    "        self.text_input.setPlaceholderText(\"번역할 텍스트 입력\")\n",
    "        self.translate_button = QtWidgets.QPushButton(\"번역 및 음성 생성\", self)\n",
    "        self.output_label = QtWidgets.QLabel(self)\n",
    "        self.play_button = QtWidgets.QPushButton(\"음성 재생\", self)\n",
    "        self.play_button.setEnabled(False)\n",
    "\n",
    "        # 레이아웃 설정\n",
    "        layout = QtWidgets.QVBoxLayout()\n",
    "        layout.addWidget(self.text_input)\n",
    "        layout.addWidget(self.translate_button)\n",
    "        layout.addWidget(self.output_label)\n",
    "        layout.addWidget(self.play_button)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "        # 버튼 클릭 시 이벤트 핸들러 연결\n",
    "        self.translate_button.clicked.connect(self.translate_and_generate_audio)\n",
    "        self.play_button.clicked.connect(self.play_audio)\n",
    "\n",
    "        # 윈도우 창 설정\n",
    "        self.setWindowTitle(\"번역 및 음성 생성기\")\n",
    "        self.show()\n",
    "\n",
    "    def translate_and_generate_audio(self):\n",
    "        text = self.text_input.text()\n",
    "\n",
    "        # 번역 수행\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        generated_tokens = self.model.generate(inputs.input_ids, forced_bos_token_id=self.tokenizer.lang_code_to_id[\"kor_Hang\"])\n",
    "        translated_text = self.tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "        # 음성 생성 요청\n",
    "        data = {\n",
    "            \"text\": translated_text,\n",
    "            \"model_id\": \"eleven_multilingual_v2\",\n",
    "            \"voice_settings\": {\n",
    "                \"stability\": 0.5,\n",
    "                \"similarity_boost\": 1,\n",
    "                \"style\": 0.5,\n",
    "                \"use_speaker_boost\": True\n",
    "            }\n",
    "        }\n",
    "        headers = {\n",
    "            \"xi-api-key\": self.api_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        response = requests.post(self.url, json=data, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            output_audio_path = \"audio_output/output_audio.mp3\"\n",
    "            with open(output_audio_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            self.output_label.setText(f\"번역 결과: {translated_text}\")\n",
    "            self.play_button.setEnabled(True)\n",
    "        else:\n",
    "            self.output_label.setText(\"음성 생성 실패\")\n",
    "\n",
    "    def play_audio(self):\n",
    "        # 음성 파일 재생\n",
    "        audio_path = \"audio_output/output_audio.mp3\"\n",
    "        if os.path.exists(audio_path):\n",
    "            # Pydub을 통해 mp3 파일을 불러와서 재생\n",
    "            audio = AudioSegment.from_mp3(audio_path)\n",
    "            webbrowser.open(audio)\n",
    "        else:\n",
    "            self.output_label.setText(\"오디오 파일을 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app = QtWidgets.QApplication([])\n",
    "    translator = TranslatorApp()\n",
    "    app.exec_()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
