{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI ëª¨ë¸ í™œìš© 1ì£¼ì°¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "12.4\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My name is\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[3666, 1438,  318]]), 'attention_mask': tensor([[1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(encoded_input['input_ids'], max_length=50)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My name is John. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a man of God. I'm a\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3666, 1438,  318, 1757,   13,  314, 1101,  257,  582,  286, 1793,   13,\n",
       "          314, 1101,  257,  582,  286, 1793,   13,  314, 1101,  257,  582,  286,\n",
       "         1793,   13,  314, 1101,  257,  582,  286, 1793,   13,  314, 1101,  257,\n",
       "          582,  286, 1793,   13,  314, 1101,  257,  582,  286, 1793,   13,  314,\n",
       "         1101,  257]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI ëª¨ë¸ í™œìš© 2ì£¼ì°¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorchë¥¼ í™œìš©í•˜ì—¬ Transformer ëª¨ë¸ êµ¬í˜„í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ì¤€ë¹„\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(num_epochs):\\n    optimizer.zero_grad()\\n    output = model(src, tgt)\\n    loss = criterion(output, tgt_labels)\\n    loss.backward()\\n    optimizer.step()\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ\n",
    "\"\"\"\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(src, tgt)\n",
    "    loss = criterion(output, tgt_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ í™œìš©í•˜ê¸°\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "cache_path = 'D:\\Anaconda3_envs\\SpartaCodingClub\\SpartaCodingClub\\main_camp'\n",
    "\n",
    "torch.hub.set_dir(cache_path)\n",
    "model = AutoModelForCausalLM.from_pretrained('gpt2', cache_dir=cache_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2', cache_dir=cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'Once upon a time'\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input_ids, max_length=50, num_return_sequences = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI ëª¨ë¸ í™œìš© 3ì£¼ì°¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert_Basic.py & transformers_code.py ì°¸ê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI ëª¨ë¸ í™œìš© 4ì£¼ì°¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time the same happened to the ancient Egyptian, the Egyptian man who had long ago vanquished the evil gods is made a mortal for each of a man's deeds. Now it is clear that the same god is given immortality to a man that\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# GPT-2 ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ\n",
    "generator = pipeline(\"text-generation\", model='gpt2', device=device)\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ìƒì„±\n",
    "generated_text = generator(\"Once upon a time\", max_length=50, num_return_sequences=1, truncation=True)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ì•ˆë…•! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ! í˜¹ì‹œ ì—¬ê¸° ì˜¬ ë•Œ \"ì „ììš°ì²´êµ­\"ì—ì„œ ë¹„í–‰ê¸°ë¡œ ì˜¤ì…¨ë‚˜ìš”? ì•„ë‹ˆë©´ ë¹›ì˜ ì†ë„ë¡œ ì›Œí”„í•˜ì…¨ë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"ë„ˆëŠ” í™˜ì˜ ì¸ì‚¬ë¥¼ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ì•¼, ë†ë‹´ì„ ë„£ì–´ ì¬ë¯¸ìˆê²Œí•´ì¤˜\"},\n",
    "    {\"role\": \"user\", \"content\": \"ì•ˆë…•?\"}  \n",
    "  ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)\n",
    "\n",
    "# ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. ì €ë‘ ì–˜ê¸°í•˜ë‹¤ê°€ ì¬ë¯¸ ì—†ìœ¼ë©´ ì´ë ‡ê²Œ ìƒê°í•´ë³´ì„¸ìš”: ì ì–´ë„ ì—‰ë©ì´ì— ê¼¬ë¦¬ ë‹¬ë¦° ì›ìˆ­ì´ì™€ëŠ” ë‹¤ë¥´ê²Œ, ì €ëŠ” í‰ë²”í•˜ê²Œ ë¬´ë¦¬í•˜ì§€ ì•Šê±°ë“ ìš”! ë­ë“  ë¬¼ì–´ë³´ì„¸ìš”, ë„ì™€ë“œë¦´ê²Œìš”! ğŸ˜„ \n",
    "\n",
    "# ê°•ì‚¬ì˜ í•œë§ˆë””: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:53<00:00,  7.58s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:09<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# Stable Diffusion íŒŒì´í”„ë¼ì¸ ë¡œë“œ\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to('cuda')  # GPU ì‚¬ìš©\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì„¤ëª…ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "prompt = \"A futuristic cityscape with flying cars at sunset\"\n",
    "image = pipe(prompt).images[0]\n",
    "\n",
    "# ìƒì„±ëœ ì´ë¯¸ì§€ ì €ì¥ ë° ì¶œë ¥\n",
    "image.save(\"generated_image.png\")\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI ëª¨ë¸ í™œìš© 5ì£¼ì°¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API ì‹¬í™” ë° ê°„ë‹¨í•œ ì‹¤ìŠµ (FastAPI í™œìš©) -> FastAPI.py ì°¸ê³ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPTì™€ ElevenLabs ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ì•ˆë…•í•˜ì„¸ìš”, ìœ¤ìˆ˜ìš©ë‹˜. ë²•ë¥  ìƒë‹´ì´ í•„ìš”í•˜ì‹ ê°€ìš”? ì–´ë–¤ ì ì´ ê¶ê¸ˆí•˜ì‹ ì§€ ë§ì”€í•´ì£¼ì‹œë©´ ë„ì›€ì´ ë  ìˆ˜ ìˆëŠ” ë°©í–¥ìœ¼ë¡œ ì•ˆë‚´í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# API í‚¤ë¥¼ ëª» ê°€ì ¸ì™”ì„ ê²½ìš° ì—ëŸ¬ í‘œì‹œ \n",
    "if api_key is None:\n",
    "    raise ValueError('Failed loading')\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = api_key\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ë³€í˜¸ì‚¬ì•¼ ë‚˜ì—ê²Œ ë²•ì ì¸ ìƒë‹´ì„ í•´ì¤˜\"},\n",
    "        {\"role\": \"user\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš” ì €ëŠ” ìœ¤ìˆ˜ìš©ì…ë‹ˆë‹¤.\"}  \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Assistant: \" + completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€ë‹µ:  ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ë²•ë¥  ê´€ë ¨ ìƒë‹´ì´ í•„ìš”í•˜ì‹ ê°€ìš”?\n",
      "ëŒ€ë‹µ:  ë¶€ê°€ê°€ì¹˜ì„¸(VAT)ëŠ” ìƒí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ê°€ ìƒì‚° ë° ìœ í†µë˜ëŠ” ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë¶€ê°€ê°€ì¹˜ì— ëŒ€í•´ ë¶€ê³¼ë˜ëŠ” ì„¸ê¸ˆì„ ë§í•©ë‹ˆë‹¤. í•œêµ­ì—ì„œëŠ” ì‚¬ì—…ìê°€ ì†Œë¹„ìë¡œë¶€í„° ìƒí’ˆì´ë‚˜ ì„œë¹„ìŠ¤ íŒë§¤ ì‹œ ë¶€ê°€ê°€ì¹˜ì„¸ë¥¼ ì§•ìˆ˜í•˜ê³ , ì´í›„ ì •ë¶€ì— ì´ë¥¼ ë‚©ë¶€í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œëŠ” íŒë§¤ ê°€ê²©ì— 10%ì˜ ì„¸ìœ¨ì´ ì ìš©ë©ë‹ˆë‹¤.\n",
      "\n",
      "ë¶€ê°€ê°€ì¹˜ì„¸ì˜ íŠ¹ì§• ì¤‘ í•˜ë‚˜ëŠ” ì‚¬ì—…ìê°€ ë§¤ì… ì‹œ ë¶€ë‹´í–ˆë˜ ë¶€ê°€ê°€ì¹˜ì„¸ë¥¼ ê³µì œë°›ì„ ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì¦‰, ì‚¬ì—…ìëŠ” íŒë§¤ ì‹œ ì§•ìˆ˜í•œ ë¶€ê°€ê°€ì¹˜ì„¸ì—ì„œ ë§¤ì… ì‹œ ë‚©ë¶€í•œ ë¶€ê°€ê°€ì¹˜ì„¸ë¥¼ ì°¨ê°í•œ ê¸ˆì•¡ë§Œí¼ì„ êµ­ê°€ì— ë‚©ë¶€í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ì´ì¤‘ê³¼ì„¸ë¥¼ ë°©ì§€í•˜ê³ , ì„¸ê¸ˆ ë¶€ë‹´ì´ ìµœì¢… ì†Œë¹„ìì—ê²Œ ì „ê°€ë˜ë„ë¡ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë¶€ê°€ê°€ì¹˜ì„¸ëŠ” ëŒ€ë¶€ë¶„ì˜ ìƒí’ˆê³¼ ì„œë¹„ìŠ¤ì— ì ìš©ë˜ì§€ë§Œ, ì¼ë¶€ ë©´ì„¸ ëŒ€ìƒë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê¸°ì´ˆ ì‹ë£Œí’ˆ, ì˜ë£Œ ì„œë¹„ìŠ¤, êµìœ¡ ì„œë¹„ìŠ¤ ë“±ì€ ë¶€ê°€ê°€ì¹˜ì„¸ê°€ ë©´ì œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ì—…ìëŠ” ì •ê¸°ì ìœ¼ë¡œ ë¶€ê°€ê°€ì¹˜ì„¸ ì‹ ê³ ì™€ ë‚©ë¶€ë¥¼ í•´ì•¼ í•˜ë©°, ì´ë¥¼ í†µí•´ êµ­ê°€ì˜ ì„¸ìˆ˜ í™•ë³´ì™€ ê²½ì œ í™œë™ì˜ íˆ¬ëª…ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "ëŒ€ë‹µ:  ì¦ê±°ìš´ ëŒ€í™”ì˜€ìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "system_message =  {\n",
    "    \"role\": \"system\", \"content\": \"ë„ˆëŠ” ë³€í˜¸ì‚¬ì•¼ ë‚˜ì—ê²Œ ë²•ë¥ ì ì¸ ìƒë‹´ì„ í•´ì¤˜. ê·¸ë¦¬ê³  ì£¼ì˜ì‚¬í•­ì€ ë§í•˜ì§€ë§ˆ. í•œêµ­ë²•ì„ ê¸°ì¤€ìœ¼ë¡œ \"\n",
    "}\n",
    "\n",
    "messages = [system_message]\n",
    "\n",
    "while True :\n",
    "    user_input = input(\"ì‚¬ìš©ì ì „ë‹¬:\")\n",
    "    if user_input == \"exit\":\n",
    "        print(\"ëŒ€ë‹µ:  ì¦ê±°ìš´ ëŒ€í™”ì˜€ìŠµë‹ˆë‹¤! ê°ì‚¬í•©ë‹ˆë‹¤!\")\n",
    "        break\n",
    "\n",
    "    messages.append({\"role\" : \"user\" , \"content\" : user_input })\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages = messages\n",
    "    )\n",
    "\n",
    "    reply = completion.choices[0].message.content\n",
    "    print(\"ëŒ€ë‹µ:  \" + reply)\n",
    "    messages.append({\"role\" : \"assistant\" , \"content\" : reply })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Wrote audio to output_audio.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "from pydub import AudioSegment\n",
    "from dotenv import load_dotenv\n",
    "import webbrowser\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ì™€ URL ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "url = os.getenv(\"ELEVENLABS_API_URL\")\n",
    "\n",
    "# API í‚¤ or URL ì„ ëª» ê°€ì ¸ì™”ì„ ê²½ìš° ì—ëŸ¬ í‘œì‹œ \n",
    "if api_key is None or url is None:\n",
    "    raise ValueError('Failed loading')\n",
    "\n",
    "output_filename = \"output_audio.mp3\"\n",
    "\n",
    "headers = {\n",
    "    \"xi-api-key\": api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "text = input(\"ìƒì„±í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# ìŒì„± ìƒì„± ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "data = {\n",
    "    \"text\": text,\n",
    "    \"model_id\": \"eleven_multilingual_v2\",\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.3,\n",
    "        \"similarity_boost\": 1,\n",
    "        \"style\": 1,\n",
    "        \"use_speaker_boost\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data, headers=headers, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    audio_content = b\"\"\n",
    "    for chunk in response.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            audio_content += chunk\n",
    "\n",
    "    segment = AudioSegment.from_mp3(io.BytesIO(audio_content))\n",
    "    segment.export(output_filename, format=\"mp3\")\n",
    "    print(f\"Success! Wrote audio to {output_filename}\")\n",
    "\n",
    "    # ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤.\n",
    "    webbrowser.open(output_filename)\n",
    "else:\n",
    "    print(f\"Failed to save file: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultralytics YOLOë¥¼ í™œìš©í•œ ì´ë¯¸ì§€ ê°ì²´ íƒì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 62.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# YOLOv8 ëª¨ë¸ ë¡œë“œ (YOLOv8s)\n",
    "model = YOLO('yolov8n.pt')  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›¹ìº ì„ í†µí•´ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€\n",
    "cap = cv2.VideoCapture(0)  # ì›¹ìº  ìº¡ì²˜ ì‹œì‘\n",
    "cap.set(360, 480)\n",
    "# ì›¹ìº  -> \n",
    "\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "  if not ret:\n",
    "    break\n",
    "\n",
    "  # í”„ë ˆì„ì„ YOLOv8 ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ê°ì²´ íƒì§€ ìˆ˜í–‰\n",
    "  results = model(frame)\n",
    "  \n",
    "  # ì´í›„ ì²˜ë¦¬ì½”ë“œ    \n",
    "  cv2.imshow('webcam', frame)\n",
    "\n",
    "  # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "# ì›¹ìº  ì¢…ë£Œ ë° ì°½ ë‹«ê¸°\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCVì™€ YOLOë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì„œë¹„ìŠ¤ ë§Œë“¤ì–´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from PyQt5.QtWidgets import QApplication, QLabel, QVBoxLayout, QWidget, QPushButton\n",
    "from PyQt5.QtCore import QTimer\n",
    "from PyQt5.QtGui import QImage, QPixmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoCaptureWidget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # YOLOv8x ëª¨ë¸ ë¡œë“œ (YOLOv8x)\n",
    "        self.model = YOLO('yolov8x.pt')\n",
    "        \n",
    "        # UI ì„¤ì •\n",
    "        self.setWindowTitle(\"ì‹¤ì‹œê°„ ê°ì²´ íƒì§€\")\n",
    "        self.image_label = QLabel(self)\n",
    "        self.layout = QVBoxLayout()\n",
    "        self.layout.addWidget(self.image_label)\n",
    "\n",
    "        self.start_button = QPushButton(\"Start Webcam\", self)\n",
    "        self.start_button.clicked.connect(self.start_webcam)\n",
    "        self.layout.addWidget(self.start_button)\n",
    "\n",
    "        self.stop_button = QPushButton(\"Stop Webcam\", self)\n",
    "        self.stop_button.clicked.connect(self.stop_webcam)\n",
    "        self.layout.addWidget(self.stop_button)\n",
    "        self.setLayout(self.layout)\n",
    "        \n",
    "        # ì›¹ìº  ì´ˆê¸°í™”\n",
    "        self.capture = None\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.timeout.connect(self.update_frame)\n",
    "\n",
    "    def stop_webcam(self):\n",
    "        \"\"\"ì›¹ìº ì„ ì¤‘ì§€í•˜ê³  íƒ€ì´ë¨¸ë¥¼ ë©ˆì¶¤\"\"\"\n",
    "        self.timer.stop()\n",
    "        if self.capture is not None:\n",
    "            self.capture.release()\n",
    "    \n",
    "    def start_webcam(self):\n",
    "        \"\"\"ì›¹ìº ì„ ì‹œì‘í•˜ê³ , íƒ€ì´ë¨¸ë¥¼ ì‹œì‘í•˜ì—¬ í”„ë ˆì„ì„ ì£¼ê¸°ì ìœ¼ë¡œ ì½ìŒ\"\"\"\n",
    "        self.capture = cv2.VideoCapture(0)  # ì›¹ìº  ì¥ì¹˜ ì—´ê¸°\n",
    "        self.timer.start(20)  # 20msë§ˆë‹¤ í”„ë ˆì„ ì—…ë°ì´íŠ¸ (50fps)\n",
    "\n",
    "    def update_frame(self):\n",
    "        \"\"\"ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ì½ì–´ì™€ì„œ YOLO ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•œ í›„ UIì— í‘œì‹œ\"\"\"\n",
    "        ret, frame = self.capture.read()\n",
    "        if ret:\n",
    "            # YOLOv8 ê°ì²´ íƒì§€ ìˆ˜í–‰\n",
    "            results = self.model(frame)\n",
    "            result = results[0]\n",
    "\n",
    "            # ë°”ìš´ë”© ë°•ìŠ¤ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì˜´\n",
    "            img_with_boxes = result.plot()\n",
    "\n",
    "            # OpenCV ì´ë¯¸ì§€ë¥¼ QImageë¡œ ë³€í™˜\n",
    "            rgb_image = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
    "            h, w, ch = rgb_image.shape\n",
    "            bytes_per_line = ch * w\n",
    "            convert_to_Qt_format = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "\n",
    "            # QImageë¥¼ QLabelì— í‘œì‹œí•˜ê¸° ìœ„í•´ QPixmapìœ¼ë¡œ ë³€í™˜\n",
    "            self.image_label.setPixmap(QPixmap.fromImage(convert_to_Qt_format))\n",
    "    \n",
    "    def closeEvent(self, event):\n",
    "        \"\"\"ìœˆë„ìš° ë‹«ì„ ë•Œ ì›¹ìº  í•´ì œ\"\"\"\n",
    "        if self.capture is not None:\n",
    "            self.capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication([])\n",
    "    window = VideoCaptureWidget()\n",
    "    window.show()\n",
    "    app.exec_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatGPTì™€ FastAPIë¥¼ í™œìš©í•œ ì±— ì„œë¹„ìŠ¤ ë§Œë“¤ì–´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request, Form\n",
    "from fastapi.templating import Jinja2Templates\n",
    "from fastapi.responses import HTMLResponse\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "from openai import OpenAI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# OpenAI API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "client = OpenAI()\n",
    "\n",
    "# Jinja2 í…œí”Œë¦¿ ì„¤ì •\n",
    "templates = Jinja2Templates(directory=\"./app/templates\")\n",
    "\n",
    "# ì •ì  íŒŒì¼ ì„œë¹™\n",
    "app.mount(\"/static\", StaticFiles(directory=\"./app/static\"), name=\"static\")\n",
    "\n",
    "# ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„¤ì •\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"ë„ˆëŠ” í™˜ì˜ ì¸ì‚¬ë¥¼ í•˜ëŠ” ì¸ê³µì§€ëŠ¥ì´ì•¼, ë†ë‹´ì„ ë„£ì–´ ì¬ë¯¸ìˆê²Œí•´ì¤˜\"\n",
    "}\n",
    "\n",
    "# ëŒ€í™” ë‚´ì—­ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”\n",
    "messages = [system_message]\n",
    "\n",
    "@app.get(\"/\", response_class=HTMLResponse)\n",
    "async def get_chat_page(request: Request):\n",
    "    \"\"\"ì±„íŒ… í˜ì´ì§€ ë Œë”ë§\"\"\"\n",
    "    conversation_history = [msg for msg in messages if msg[\"role\"] != \"system\"]\n",
    "    return templates.TemplateResponse(\"index.html\", {\"request\": request, \"conversation_history\": conversation_history})\n",
    "\n",
    "@app.post(\"/chat\", response_class=HTMLResponse)\n",
    "async def chat(request: Request, user_input: str = Form(...)):\n",
    "    \"\"\"ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë°›ì•„ OpenAI API í˜¸ì¶œ ë° ì‘ë‹µ ë°˜í™˜\"\"\"\n",
    "    global messages\n",
    "\n",
    "    # ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # OpenAI API í˜¸ì¶œ\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    # AIì˜ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°\n",
    "    assistant_reply = completion.choices[0].message.content\n",
    "\n",
    "    # AIì˜ ì‘ë‹µì„ ëŒ€í™” ë‚´ì—­ì— ì¶”ê°€\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "\n",
    "    # í™”ë©´ì— í‘œì‹œí•  ëŒ€í™” ë‚´ì—­ì—ì„œ system ë©”ì‹œì§€ë¥¼ ì œì™¸í•˜ê³  ì „ë‹¬\n",
    "    conversation_history = [msg for msg in messages if msg[\"role\"] != \"system\"]\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ HTMLë¡œ ë°˜í™˜ (ëŒ€í™” ë‚´ì—­ê³¼ í•¨ê»˜)\n",
    "    return templates.TemplateResponse(\"index.html\", {\n",
    "        \"request\": request,\n",
    "        \"conversation_history\": conversation_history\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìŒì„± ìƒì„±ê³¼ ë²ˆì—­ì„ í™œìš©í•œ ë²ˆì—­ ì„œë¹„ìŠ¤ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\SpartaCodingClub\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5.QtCore import QUrl\n",
    "from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from pydub import AudioSegment\n",
    "import webbrowser\n",
    "import io\n",
    "\n",
    "class TranslatorApp(QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_ui()\n",
    "\n",
    "        # ë²ˆì—­ ëª¨ë¸ ë¡œë“œ\n",
    "        model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "        # API ì„¤ì •\n",
    "        load_dotenv()\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.url = os.getenv(\"ELEVENLABS_API_URL\")\n",
    "\n",
    "        # ìŒì„± ì¬ìƒê¸°\n",
    "        self.player = QMediaPlayer()\n",
    "\n",
    "    def init_ui(self):\n",
    "        # UI êµ¬ì„±\n",
    "        self.text_input = QtWidgets.QLineEdit(self)\n",
    "        self.text_input.setPlaceholderText(\"ë²ˆì—­í•  í…ìŠ¤íŠ¸ ì…ë ¥\")\n",
    "        self.translate_button = QtWidgets.QPushButton(\"ë²ˆì—­ ë° ìŒì„± ìƒì„±\", self)\n",
    "        self.output_label = QtWidgets.QLabel(self)\n",
    "        self.play_button = QtWidgets.QPushButton(\"ìŒì„± ì¬ìƒ\", self)\n",
    "        self.play_button.setEnabled(False)\n",
    "\n",
    "        # ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
    "        layout = QtWidgets.QVBoxLayout()\n",
    "        layout.addWidget(self.text_input)\n",
    "        layout.addWidget(self.translate_button)\n",
    "        layout.addWidget(self.output_label)\n",
    "        layout.addWidget(self.play_button)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "        # ë²„íŠ¼ í´ë¦­ ì‹œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°\n",
    "        self.translate_button.clicked.connect(self.translate_and_generate_audio)\n",
    "        self.play_button.clicked.connect(self.play_audio)\n",
    "\n",
    "        # ìœˆë„ìš° ì°½ ì„¤ì •\n",
    "        self.setWindowTitle(\"ë²ˆì—­ ë° ìŒì„± ìƒì„±ê¸°\")\n",
    "        self.show()\n",
    "\n",
    "    def translate_and_generate_audio(self):\n",
    "        text = self.text_input.text()\n",
    "\n",
    "        # ë²ˆì—­ ìˆ˜í–‰\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        generated_tokens = self.model.generate(inputs.input_ids, forced_bos_token_id=self.tokenizer.lang_code_to_id[\"kor_Hang\"])\n",
    "        translated_text = self.tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "        # ìŒì„± ìƒì„± ìš”ì²­\n",
    "        data = {\n",
    "            \"text\": translated_text,\n",
    "            \"model_id\": \"eleven_multilingual_v2\",\n",
    "            \"voice_settings\": {\n",
    "                \"stability\": 0.5,\n",
    "                \"similarity_boost\": 1,\n",
    "                \"style\": 0.5,\n",
    "                \"use_speaker_boost\": True\n",
    "            }\n",
    "        }\n",
    "        headers = {\n",
    "            \"xi-api-key\": self.api_key,\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        response = requests.post(self.url, json=data, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            output_audio_path = \"audio_output/output_audio.mp3\"\n",
    "            with open(output_audio_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            self.output_label.setText(f\"ë²ˆì—­ ê²°ê³¼: {translated_text}\")\n",
    "            self.play_button.setEnabled(True)\n",
    "        else:\n",
    "            self.output_label.setText(\"ìŒì„± ìƒì„± ì‹¤íŒ¨\")\n",
    "\n",
    "    def play_audio(self):\n",
    "        # ìŒì„± íŒŒì¼ ì¬ìƒ\n",
    "        audio_path = \"audio_output/output_audio.mp3\"\n",
    "        if os.path.exists(audio_path):\n",
    "            # Pydubì„ í†µí•´ mp3 íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ì¬ìƒ\n",
    "            audio = AudioSegment.from_mp3(audio_path)\n",
    "            webbrowser.open(audio)\n",
    "        else:\n",
    "            self.output_label.setText(\"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app = QtWidgets.QApplication([])\n",
    "    translator = TranslatorApp()\n",
    "    app.exec_()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
